{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for fetching HTML/ content from webpages\n",
    "from bs4 import BeautifulSoup as bs # BeautifulSoup allows us to work with the HTML and display the data\n",
    "import csv # Importing CSV so the data can be written to an Exdel file \n",
    "import pandas as pd #importing pandas enables data anlysis\n",
    "\n",
    "outfile = open('Pioneerscrape.csv', 'w', newline='') # Defining the output file name and perameters such as \"w\" which stands for write\n",
    "writer = csv.writer(outfile)\n",
    "\n",
    "#define dataframe\n",
    "df = pd.DataFrame(columns=['instock', 'price'])\n",
    "\n",
    "\n",
    "# setting the web scrapers below. Using parts of the website im interested in. The information was found by 'inspecting' the webpage \n",
    "def scrape_web_1(soup):\n",
    "    lists = soup.find_all('section', class_='cs-buybox__section')\n",
    "    price = soup.find('span', class_=\"price\")\n",
    "    instock = soup.find('span', class_=\"cs-buybox__stock-text\")\n",
    "    result = [ lists, price, instock ]\n",
    "    return result\n",
    "\n",
    "def scrape_web_2(soup):\n",
    "    lists = soup.find_all('section', class_='info-row')\n",
    "    price = soup.find('span', class_=\"c-val\")\n",
    "    instock = soup.find('div', class_=\"tooltip-source info-row-stock-msg nostock can-order\")\n",
    "    result = [ lists, price, instock ]\n",
    "    return result\n",
    "\n",
    "# Defining the URL's \n",
    "web_1 = 'https://www.tamsta.com/en/dj-controller-pioneer-ddj-1000'\n",
    "web_2 = 'https://www.gear4music.com/PA-DJ-and-Lighting/Pioneer-DJ-DDJ-1000-Rekordbox-DJ-Controller/2ACE'\n",
    "\n",
    "\n",
    "# Asking the scraper/ BeautifulSoup to fetch webpage1 (and2) and parsing to HTML\n",
    "req = requests.get(web_1)\n",
    "soup = bs(req.text, 'html.parser')\n",
    "result = scrape_web_1(soup)\n",
    "\n",
    "req = requests.get(web_2)\n",
    "soup = bs(req.text, 'html.parser')\n",
    "result2 = scrape_web_2(soup)\n",
    "\n",
    "\n",
    "#save to CSV\n",
    "df.to_csv('scrape.csv')\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], <span class=\"c-val\" content=\"1223.52\">1,223.52</span>, <div class=\"tooltip-source info-row-stock-msg nostock can-order\">\n",
      "      Available for order   </div>]\n"
     ]
    }
   ],
   "source": [
    " print(result2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
